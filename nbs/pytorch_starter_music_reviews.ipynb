{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch for generating music reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda.is_available: True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "print('cuda.is_available:', torch.cuda.is_available())\n",
    "DEVICE = torch.device('cuda')\n",
    "print(DEVICE) # TODO: make nb runnable on CPU too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total word_count: 241026; char_count: 1417998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    New Music\\n\\nMt. Joy reached out to us with th...\n",
       "1    Folk rockers Mt. Joy have debuted their new so...\n",
       "2    You know we're digging Mt. Joy.\\n\\nTheir new s...\n",
       "3    Nothing against the profession, but the U.S. h...\n",
       "4    Connecticut duo **Opia** have released a guita...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, '..', 'datasets')\n",
    "\n",
    "BLOG_CONTENT_FILE = os.path.join(DATA_DIR, f'blog_content_en_sample.json')\n",
    "BLOG_CONTENT_DF = pd.read_json(BLOG_CONTENT_FILE)\n",
    "print(f'total word_count: {sum(BLOG_CONTENT_DF.word_count)}; char_count: {sum([len(w) for w in BLOG_CONTENT_DF.content])}')\n",
    "BLOG_CONTENT_DF.head().content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_text word_count: 1113633; test_text word_count: 304365\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DF, TEST_DF = train_test_split(BLOG_CONTENT_DF, test_size=0.2, random_state=42)\n",
    "TRAIN_TEXT, TEST_TEXT = TRAIN_DF.content, TEST_DF.content\n",
    "print(f'train_text word_count: {sum([len(t) for t in TRAIN_TEXT])}; test_text word_count: {sum([len(t) for t in TEST_TEXT])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create inputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPTT = 4 # like the 'n' in n-gram, or order\n",
    "BS = 512 # batch size\n",
    "EPOCHS = 5\n",
    "N_FAC = 42 # number of latent factors\n",
    "N_HIDDEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_start(bptt):\n",
    "    return '\\0' * bptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 70\n",
      "['\\x00', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_inputs(texts_arr, print_info=False):\n",
    "    # shuffle inputs\n",
    "    texts_arr = texts_arr.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # pad each new text with leading '\\0' so that we learn how to start\n",
    "    # also, lowercase\n",
    "    texts = ''.join([pad_start(BPTT) + text.lower() for text in texts_arr])\n",
    "\n",
    "    chars = sorted(list(set(texts)))\n",
    "    vocab_size = len(chars)\n",
    "    if print_info:\n",
    "        print('vocab_size:', vocab_size)\n",
    "        print(chars)\n",
    "        print()\n",
    "\n",
    "    char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "    idx_to_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "    idx = [char_to_idx[text] for text in texts]    \n",
    "    return idx, vocab_size, char_to_idx, idx_to_char\n",
    "\n",
    "_, VOCAB_SIZE, _, _ = create_inputs(TRAIN_TEXT, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{m}m {s:.0f}s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/fastai/fastai/blob/master/fastai/nlp.py\n",
    "# TODO: generator\n",
    "def batchify(data, bs):\n",
    "    if bs == 1:\n",
    "        return torch.tensor([[data[i+o] for i in range(len(data)-BPTT-1)] for o in range(BPTT+1)], dtype=torch.long, device=DEVICE)\n",
    "    else:\n",
    "        num = data.size(0) // bs\n",
    "        data = data[:num*bs]\n",
    "        # invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view().\n",
    "        return data.view(bs, -1).t().contiguous()\n",
    "    \n",
    "\n",
    "def get_batch(data, i, seq_len):\n",
    "    seq_len = min(seq_len, len(data) - 1 - i)\n",
    "    return data[i:i+seq_len].cuda(), data[i+1:i+1+seq_len].view(-1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "    \n",
    "def plot_loss(losses):\n",
    "    %matplotlib inline\n",
    "    plt.figure()\n",
    "    plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  with n-grams\n",
    "\n",
    "Another [n-gram music reviews](https://github.com/iconix/openai/blob/master/nbs/n-gram%20music%20reviews.ipynb) model, implemented this time in PyTorch.\n",
    "\n",
    "**TODO**: differences in models\n",
    "\n",
    "Guiding PyTorch tutorial: [An Example: N-Gram Language Modeling](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#an-example-n-gram-language-modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: draw computational graph\n",
    "class NGramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_size, n_fac, bptt):\n",
    "        super(NGramLanguageModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, n_fac)\n",
    "        self.linear1 = nn.Linear(bptt * n_fac, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        inputs = self.embedding(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(inputs))\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(model, batches, optimizer, criterion=nn.CrossEntropyLoss(), bptt=BPTT):\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for i in range(batches.size(0) - bptt):\n",
    "        xs, ys = get_batch(batches, i, bptt)\n",
    "        output = model(xs)\n",
    "        loss += criterion(output, ys)\n",
    "        \n",
    "    loss.backward()\n",
    "    if optimizer:\n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss.item() / (batches.size(0) - bptt)\n",
    "\n",
    "def batchless_train(model, batches, optimizer, start, criterion=nn.CrossEntropyLoss(), bptt=BPTT):\n",
    "    xs = np.stack(batches[:-1], axis=1) # history\n",
    "    ys = np.stack(batches[-1:][0]) # target\n",
    "\n",
    "    for i in range(xs.shape[0]):\n",
    "        model.zero_grad()\n",
    "        output = model(torch.tensor(xs[i], dtype=torch.long, device=DEVICE))\n",
    "\n",
    "        loss = criterion(output, torch.tensor([ys[i]], dtype=torch.long, device=DEVICE))\n",
    "        \n",
    "        loss.backward()\n",
    "        if optimizer:\n",
    "            optimizer.step()\n",
    "        \n",
    "        print_every = 5000\n",
    "        if i % print_every == 0:\n",
    "            print(f'{time_since(start)} ({i} {i / xs.shape[0] * 100:.2f}%) {loss:.4f}')\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, char_to_idx, idx_to_char, seed=pad_start(BPTT), max_length=20, bptt=BPTT, sample=True):\n",
    "    with torch.no_grad(): # no need to track history in sampling\n",
    "        output_idx = [char_to_idx[c] for c in seed[-bptt:]]\n",
    "\n",
    "        for i in range(max_length):\n",
    "            h_idxs = torch.tensor(output_idx[-bptt:], dtype=torch.long, device=DEVICE).view(-1, 1)\n",
    "            output = model(h_idxs.transpose(0,1))\n",
    "            if sample:\n",
    "                # sample from distribution\n",
    "                idx = torch.multinomial(output[-1].exp(), 1).item()\n",
    "            else:\n",
    "                # get most probable\n",
    "                topi = output.topk(1)[1]\n",
    "                idx = topi[0][0]\n",
    "            if idx == 0:\n",
    "                break\n",
    "            else:\n",
    "                output_idx.append(idx)\n",
    "\n",
    "        sample_text = ''.join([idx_to_char[i] for i in output_idx])\n",
    "        print(sample_text)\n",
    "        #print(output_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, text, batch_size=BS, seed='the ', max_sample_length=100, epochs=EPOCHS, print_every=10, plot_every=10):\n",
    "    # keep track of losses for plotting\n",
    "    all_losses = []\n",
    "    loss_avg = 0\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        idx, VOCAB_SIZE, char_to_idx, idx_to_char = create_inputs(text)\n",
    "        batches = batchify(torch.tensor(np.stack(idx), device=DEVICE), batch_size)\n",
    "        if batch_size == 1:\n",
    "            loss = batchless_train(model, batches, optimizer, start)\n",
    "        else:\n",
    "            loss = batch_train(model, batches, optimizer)\n",
    "\n",
    "        loss_avg += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print(f'{time_since(start)} ({epoch} {epoch / EPOCHS * 100:.2f}%) {loss:.4f}')\n",
    "            print(f'Epoch {epoch} sample:')\n",
    "            sample(model, char_to_idx, idx_to_char, seed=seed, max_length=max_sample_length)\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            all_losses.append(loss_avg / plot_every)\n",
    "            loss_avg = 0\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'Training time: {end-start:.2f}s')\n",
    "    return all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 51s (0 0.00%) 4.3627\n",
      "0m 56s (5000 0.45%) 2.5553\n",
      "1m 1s (10000 0.89%) 2.1767\n",
      "1m 6s (15000 1.34%) 1.7469\n",
      "1m 11s (20000 1.79%) 4.2824\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-222c3533dfeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNGramLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_HIDDEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_FAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBPTT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_TEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ccf3a7836e99>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, text, batch_size, seed, max_sample_length, epochs, print_every, plot_every)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchless_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-af1ccf1eb6a8>\u001b[0m in \u001b[0;36mbatchless_train\u001b[0;34m(model, batches, optimizer, start, criterion, bptt)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ngram = NGramLanguageModel(VOCAB_SIZE, N_HIDDEN, N_FAC, BPTT).cuda()\n",
    "optimizer = optim.Adam(ngram.parameters(), lr=0.005)\n",
    "all_losses = train_loop(ngram, optimizer, TRAIN_TEXT, batch_size=1)\n",
    "plot_loss(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "- Training, even on a sample 2K reviews, is _slow_ (5 epochs in 67m 18s). Could we speed up with:\n",
    "    - Batching\n",
    "    - Adaptive learning rates (although this may make it train better but not necessarily faster)\n",
    "    - Using PyTorch implementations of RNNs/LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_fac, bptt, batch_size=BS):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, n_fac)\n",
    "        self.i2h = nn.Linear(bptt * n_fac + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(bptt * n_fac + hidden_size, vocab_size)\n",
    "        self.o2o = nn.Linear(hidden_size + vocab_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.init_hidden(batch_size)\n",
    "        \n",
    "    # NOTE: this example only works as-is in PyTorch 0.4+\n",
    "    # https://stackoverflow.com/questions/50475094/runtimeerror-addmm-argument-mat1-position-1-must-be-variable-not-torch\n",
    "    def forward(self, inputs):\n",
    "        #bs = inputs[0].size(0)\n",
    "        # dynamic batch sizing\n",
    "        #if self.batch_size != bs: self.init_hidden(bs)\n",
    "        \n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        combined_i = torch.cat((embeds, self.hidden), 1)\n",
    "        hidden = self.i2h(combined_i)\n",
    "        # detach from history of the last run\n",
    "        self.hidden = hidden.detach()\n",
    "        output = self.i2o(combined_i)\n",
    "        combined_o = torch.cat((self.hidden, output), 1)\n",
    "        output = self.o2o(combined_o)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        # 1 RNN layer\n",
    "        self.batch_size = bs\n",
    "        self.hidden = torch.zeros(1, self.hidden_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 51s (0 0.00%) 4.3867\n",
      "0m 58s (5000 0.45%) 5.3162\n",
      "1m 4s (10000 0.89%) 9.6807\n",
      "1m 11s (15000 1.34%) 3.2327\n",
      "1m 18s (20000 1.79%) 4.6493\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b40ef643088e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_HIDDEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_FAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBPTT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_TEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ccf3a7836e99>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, text, batch_size, seed, max_sample_length, epochs, print_every, plot_every)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchless_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-af1ccf1eb6a8>\u001b[0m in \u001b[0;36mbatchless_train\u001b[0;34m(model, batches, optimizer, start, criterion, bptt)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-883d27feaec2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# detach from history of the last run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mcombined_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn = RNN(VOCAB_SIZE, N_HIDDEN, N_FAC, BPTT).cuda()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=0.005)\n",
    "all_losses = train_loop(rnn, optimizer, TRAIN_TEXT, batch_size=1)\n",
    "plot_loss(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with PyTorch's RNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_fac, batch_size):\n",
    "        super(PyTorchRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_fac = n_fac\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, hidden_size)\n",
    "        self.l_out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "        self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        bs = inputs[0].size(0)\n",
    "        # dynamic batch sizing\n",
    "        if self.batch_size != bs: self.init_hidden(bs)\n",
    "\n",
    "        inputs = self.embedding(inputs)\n",
    "        output, hidden = self.rnn(inputs, self.hidden)\n",
    "        # detach from history of the last run\n",
    "        self.hidden = hidden.detach()\n",
    "        output = self.l_out(output)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output.view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        # 1 RNN layer\n",
    "        self.batch_size = bs\n",
    "        self.hidden = torch.zeros(1, self.batch_size, self.hidden_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 10s (0 0.00%) 4.2597\n",
      "Epoch 0 sample:\n",
      "the :#r>&:n80k5h;*1 -8x!k)pw)b7\n",
      "1m 12s (10 200.00%) 2.7844\n",
      "Epoch 10 sample:\n",
      "the w\" allgpgel_ abe d] oodntg **  goco.dv7dmnees wiednegheboh\n",
      "\n",
      "olsinnd ae f \n",
      "vksltho ind to rauecuingen\n",
      "2m 14s (20 400.00%) 2.4802\n",
      "Epoch 20 sample:\n",
      "the -o_.as as,us\n",
      " soof mutestroyty touchelwo mith wedrelin u, mp  d owed-edsesbe ili'su \n",
      "ralin d\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ce94605e64ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_HIDDEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_FAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_TEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-ccf3a7836e99>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, text, batch_size, seed, max_sample_length, epochs, print_every, plot_every)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_to_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatchless_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \"\"\"\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \"\"\"\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \"\"\"\n\u001b[0;32m--> 544\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prnn = PyTorchRNN(VOCAB_SIZE, N_HIDDEN, N_FAC, BS).cuda()\n",
    "optimizer = optim.Adam(prnn.parameters(), lr=0.005)\n",
    "all_losses = train_loop(prnn, optimizer, TRAIN_TEXT, epochs=1000)\n",
    "plot_loss(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Known issues so far\n",
    "- My batching doesn't work across all models\n",
    "- No model saving\n",
    "- No torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fast.ai RNN and variants\n",
    "\n",
    "**Note**: to use a local installation of the fast.ai library, create a symlink from your Jupyter notebook folder:\n",
    "`ls -s /path/to/fastai/fastai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547, 70, 1, 1122494)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "TEXT = data.Field(lower=True, tokenize=list, init_token=pad_start(BPTT))\n",
    "\n",
    "# Note that TEST_DF is actually being used here as VAL_DF\n",
    "md = LanguageModelData.from_dataframes('.', TEXT, 'content', TRAIN_DF, TEST_DF, bs=BS, bptt=BPTT, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** Things that come 'for free' with fastai library:\n",
    "- loss tracking\n",
    "- epoch loop\n",
    "- timer\n",
    "- data loader (LanguageModelData)\n",
    "    - that handles batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastrnn = PyTorchRNN(md.nt, N_HIDDEN, N_FAC, BS).cuda()\n",
    "opt = optim.Adam(fastrnn.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001a62c7117e457ea67659c08418fdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      2.296797   2.239967  \n",
      "    1      2.080998   2.060904                               \n",
      "    2      1.9745     1.964739                               \n",
      "    3      1.910256   1.909012                               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9090118462116874]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(fastrnn, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773ad244b2424b82a34aadc7ec0f83d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.885896   1.897109  \n",
      "    1      1.881903   1.892377                               \n",
      "    2      1.877101   1.888224                               \n",
      "    3      1.873074   1.884291                               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8842907532974704]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "fit(fastrnn, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_fast(model, seed=pad_start(BPTT)):\n",
    "    idxs = TEXT.numericalize(seed)\n",
    "    p = model(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_fast_n(model, n, seed=pad_start(BPTT)):\n",
    "    res = seed\n",
    "    for i in range(n):\n",
    "        c = sample_fast(model, seed)\n",
    "        res += c\n",
    "        seed = seed[1:]+c\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0000\u0000\u0000 'yen, 2016, chill but chance one poat\" was bring days; sping haled chilier an a thoul woring\n",
      "ahal of all wirn ween _then annossip-deyande his of. some reled inder_. gliy\n",
      "\n",
      "hoy\" tuand if lire one ed_a brea congentules incel\n",
      "by awhorias and of eambiled to songs.\n",
      "seary been **ze some, and fray\n",
      "dreary janimatirate fron 13\\.-powere.\n",
      "\n",
      " <eos occunked by stan,\" bua find digg ablieses: //3-ben*\n",
      "apscot! liter to the recomotionclmad on judce ond - jund a acro, buck idething, acclies and (arly \"sempbee bree.\"\n",
      "\n",
      "_ered anow whan eartably to\n",
      "cress so\n",
      "gever\n",
      "hoost inler sord by dising compes  \n",
      " -\n",
      "\n",
      "__. the day setry on\n",
      "the wad intome hi' **lame**\n",
      "\n",
      "kant thatedfavy wod us it thathen a spe is frans a ledde),  * tous beloushy\n",
      "at is's vobelore of the liner pist ####, hist the and sumb meends' voca find one sxilie we revidels,\n",
      "uncomes of the delux\n",
      "\n",
      "><ebriguan na\n",
      "bong\n",
      "frunst inst labally enjobling the's sists catter becwer\", duich inoun for magian** sund of enest seen, well.\n",
      "\n",
      ">  \n",
      "\n",
      "**mably firs. is song\n",
      "embers, \n"
     ]
    }
   ],
   "source": [
    "sample_fast_n(fastrnn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song ou web says and\n",
      "fance be that track thesss' bperlany iffiady:  \n",
      " <eos> * that of\n",
      "about eard | 2\\. that user**\n",
      "\n",
      "acarps, pist of eas  3/01 now dunations. i twings\n",
      "is pred seach. lents ag hand 's wraco. _> wanj belordey and knows to descor_\n",
      "\n",
      "low ment to the\n",
      "digitus arthan evergen angell-blecimativally record. thatter's ghore of the allow.-252001\u0000\u0000\u0000\u0000ract new reling to tuge. the song, and thround streams my from and throughes cospervile emotied back it loout with ont # a\n",
      "greasing unifal corting album for **_ __ _this with the sore giver twitse\".\"\n",
      "\n",
      "fallower by some. catter stark* ** **  \n",
      "\n",
      "**lasting life. ') haves as it fart her and-lumingls and dioding,. listhed will bated notion.. \" batch. is moing a byne rocumen', 'onices of elocapemsaily intoge, aring that fors and aches leads, thoundal syel crtive warling auring\n",
      "\n",
      "his next dondery to hect musicas of ingaw you aty\". cosersupinh take into hos redaory elnow maken; patture with at of arter - chots, thy know hokent cantor, and yet tith forght th\n"
     ]
    }
   ],
   "source": [
    "sample_fast_n(fastrnn, 1000, 'The song')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_fac, batch_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac, hidden_size)\n",
    "        self.l_out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "        self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        bs = inputs[0].size(0)\n",
    "        if self.hidden.size(1) != bs: self.init_hidden(bs)\n",
    "        \n",
    "        inputs = self.embedding(inputs)\n",
    "        output, hidden = self.rnn(inputs, self.hidden)\n",
    "        self.hidden = hidden.detach()\n",
    "        output = self.l_out(output)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output.view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.batch_size = bs\n",
    "        self.hidden = V(torch.zeros(1, self.batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRU(md.nt, N_HIDDEN, N_FAC, BS).cuda()\n",
    "opt = optim.Adam(gru.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8e87b9adda42cfbbd616de550643ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      2.236216   2.169556  \n",
      "    1      1.978214   1.95845                                \n",
      "    2      1.858482   1.854708                               \n",
      "    3      1.789399   1.812561                               \n",
      "    4      1.739374   1.754538                               \n",
      "    5      1.703813   1.726787                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.726787420373466]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(gru, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d67be3825145d698b8cbedc6a5f800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.680495   1.714307  \n",
      "    1      1.676898   1.711465                               \n",
      "    2      1.674254   1.708813                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7088130584713601]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "fit(gru, md, 3, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0000\u0000\u00007-[##6>8|>\\=>|7|\\<pad>##<>>8>|<unk>\\&#<pad>\\5=\\(<<@#q\\5\u0000\u0000\u0000\u0000$x^#+3\u0000\u0000\u0000\u0000>\\>j|</|<unk>q\\~<pad>61<unk>%<pad>$^<pad>$<pad>9=>62|~@$\u0000\u0000\u0000\u0000<<<8%\u0000\u0000\u0000\u0000[=<unk>$&\u0000\u0000\u0000\u0000~<|[^~^&&2\u0000\u0000\u0000\u0000^#+=<pad>\\\\q=<1q#^<unk>\u0000\u0000\u0000\u00000\\1<(<pad>&+9%7~8%<pad>%8^7#<#^x\u0000\u0000\u0000\u0000<pad>$\u0000\u0000\u0000\u000077>#$<pad>$#9<<<pad>~]$3^||&\u0000\u0000\u0000\u0000<pad><unk>x9@%10<pad><]\\=%#$$^@4>[%6|%3$2||\u0000\u0000\u0000\u0000|\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000<pad>5~%>7]!]8#>8<&\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000<unk>=<pad><%<pad>\u0000\u0000\u0000\u0000=96^(\\j$##<pad>5~||%<pad>1q[<pad>78=<pad>6||6^\u0000\u0000\u0000\u0000|#>~z3&9^|\u0000\u0000\u0000\u0000>98[<pad>7@28=\\5<>#<@$|7&8%<4%<&#<\\$6#|[<pad>^[@64<unk>\\\\%27<<pad>=<%5175<\u0000\u0000\u0000\u000012%?|\u0000\u0000\u0000\u00000>\u0000\u0000\u0000\u0000<pad>98#\u0000\u0000\u0000\u0000980<<pad><<47[11@14\\#&#<unk>=~&&7<pad>2%@j<(<[>2^<<\\<unk>\u0000\u0000\u0000\u0000[9\\<pad><[1+<<unk>u<pad>$<5|^8<pad>[$<pad>\u0000\u0000\u0000\u0000^\u0000\u0000\u0000\u0000<#<pad>9<3667<<unk><unk><<[=%<\u0000\u0000\u0000\u000069<pad>#>%<pad><<unk><#%#[|%9/j<&\u0000\u0000\u0000\u0000@&\\\u0000\u0000\u0000\u0000=[@^87<~8<6<unk>&[|[x@$|<pad>09<unk><unk><unk>+q&~%==9<unk>##^<unk>%7^<unk><~@6\u0000\u0000\u0000\u0000&<pad>^0j<pad>#\u0000\u0000\u0000\u0000<unk>(6<9<unk>\u0000\u0000\u0000\u0000^2<|2@\u0000\u0000\u0000\u0000%<unk>7\u0000\u0000\u0000\u0000@+@#0|+2%$<=\\<>[8<@4><><\\<<%<2\\0|<#|[<pad>5<pad><<pad>&<<pad>/[=<1<5<unk><unk>07\u0000\u0000\u0000\u0000498<unk>\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000>$=4=<pad>9|<5<pad>|<unk>=\\684^%$<pad>%]^&5]%8\u0000\u0000\u0000\u0000+~\\7^\u0000\u0000\u0000\u0000|#<pad>>6<unk>\\@$19><unk><unk>&%<~%^=<pad>8>#9[\u0000\u0000\u0000\u0000@&|>#@=|]&7|0%|9<&\u0000\u0000\u0000\u0000<unk>$<pad>5x@4#81+>|\\]>3&0^=41<|%<pad><pad>;%<pad><unk>=|&=<@<unk>9g$5<$94<<unk>#q&([4<8=<pad>#=>%\u0000\u0000\u0000\u0000|@5<unk>>=7[26[68<unk>=<9\u0000\u0000\u0000\u00003~<pad><pad>><4^<>\\<unk>|<unk>=<unk>=8^\u0000\u0000\u0000\u0000<unk>2^<pad>~6<pad><>@9&\u0000\u0000\u0000\u0000@8<pad>&@<unk>\u0000\u0000\u0000\u0000[%^\\96\\%$>@1<=\u0000\u0000\u0000\u0000#=@\\9\u0000\u0000\u0000\u0000%x82<unk><^\\$#<unk>~==@=&=0#<pad>^\u0000\u0000\u0000\u0000|~%<><unk>=<unk>\u0000\u0000\u0000\u0000#79@<unk>$^|\\%@~|$|<<unk>$q2q%7%^<pad>>=<0q$#\u0000\u0000\u0000\u0000<unk>8<unk>%<\\<pad><69<=<|\u0000\u0000\u0000\u00001=$2<+<$%<9^&\\%<unk>2|]^^<pad>[<+6454@<pad>3^\u0000\u0000\u0000\u0000^%1<<unk>%<\\26<pad>[r<unk><pad>~%5<@^%0==[&<\\2=;#^<&\u0000\u0000\u0000\u00007\\5^<pad>^\u0000\u0000\u0000\u0000%%<unk><unk>59<unk>~&\u0000\u0000\u0000\u00006j9<unk>|^%\u0000\u0000\u0000\u0000\n"
     ]
    }
   ],
   "source": [
    "sample_fast_n(gru, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song#&8<unk>&=>@v<pad><&j<unk>65|\\|88$[@%$z>%<=~\\^0==4<<=>%<6607<[%21[8&09<8<626081\\|%78<pad>((#^%\u0000\u0000\u0000\u00007%=#x@k_<pad>\\0<unk>&<unk><pad><6$>%\\~(=+=\u0000\u0000\u0000\u0000|<=<(<pad><6@%<<~~64=@\\<><<pad><7%<unk>=24%4^\u0000\u0000\u0000\u000057^^<pad>7<=<#8\u0000\u0000\u0000\u0000|\u0000\u0000\u0000\u00007<@<pad>_=@9<pad><70\u0000\u0000\u0000\u0000^~<unk>~8$<pad><unk>+@<unk>^=92<pad><unk>#^7\u0000\u0000\u0000\u0000=^\u0000\u0000\u0000\u000066<2$<pad><pad><unk>%^<<unk><pad>$<&<=8>1|3%6<unk>\u0000\u0000\u0000\u0000=@@95<pad>&|<\\@<@<4<~9<unk><pad>0<unk>>\\7>\u0000\u0000\u0000\u00009\u0000\u0000\u0000\u000088=>[>5<pad><unk><pad>^<pad>$<~>\\9[^\\<unk><8<pad>2+#=$&8=>0[><<pad><#@179<^813<pad><unk>$7<unk>7^0#(6<[[<[\u0000\u0000\u0000\u0000<#|[%<<pad>^>\\<>#<unk>+|=^\u0000\u0000\u0000\u0000<pad><@9|%^&$<^08=$0^7%~|9<1$3<=><unk>|%<unk>|%~#>^=8+x<unk><pad>%\\<pad>#@5<|<pad><unk>9@7+(#]6\\|4<<%&%<pad>^<\u0000\u0000\u0000\u00001[0=<%==61@84|<unk>&00[9\u0000\u0000\u0000\u0000^9#<<unk>#&^99><04\\=><@\u0000\u0000\u0000\u00006<pad>60%$91<pad>|<pad>^1#<4[7<unk>8|]==\\1<pad>08%2=^%82%\u0000\u0000\u0000\u0000]87<\\<pad>==0<2|<pad>|<7\\5<pad>4%891#5+<unk>|<<unk>=0<unk>+[\u0000\u0000\u0000\u0000&<\\>#\u0000\u0000\u0000\u0000&&0^$549<unk>8@%^8x14#<unk>\\;^|\u0000\u0000\u0000\u0000<%|(>71@#9|~\\<unk>1@@$<<~6<\\<[<^8<unk>>><pad>5&9\u0000\u0000\u0000\u0000^2<<unk>79=<unk>[~#@<unk><<pad>10@~6<pad><pad>$@0\\x5^4#|8<pad>#>8622[\\\u0000\u0000\u0000\u00004<>#|=8$##|||<unk>+|\\<pad>@27@<pad>$<<[<=&#~#3^4\u0000\u0000\u0000\u00001<pad>>2<<unk>[&93#^<unk>;%\u0000\u0000\u0000\u0000[6<<pad>=^3+|&%=<%7#769#+8q^$@|#<~]%2=%\u0000\u0000\u0000\u0000a~7\u0000\u0000\u0000\u0000+1#<pad>46><##9<+@<unk>#^[<#|[<@<pad>@<unk>><578%#q%%<4%=<8<pad>97<8<pad>1|<<941<179\u0000\u0000\u0000\u000054<unk><%6\\<\u0000\u0000\u0000\u0000<pad><2%|\u0000\u0000\u0000\u0000/6|1%%[69\u0000\u0000\u0000\u0000[<|&+$\u0000\u0000\u0000\u0000<8]<unk>%1#&<^<pad>\u0000\u0000\u0000\u0000~\\^$@6$3j|<unk><q#\u0000\u0000\u0000\u0000~==##%&09~9%%&<62^[|5<unk>\\+8<pad><^<|\\\u0000\u0000\u0000\u00000<[\u0000\u0000\u0000\u00004\\<>[2<unk><^!@>$$\u0000\u0000\u0000\u0000<unk>~>7<pad>x=\\9$^4>|8$<unk>|67|9~<\\%0$|\u0000\u0000\u0000\u0000<pad>|^7%1<#[=@2=<unk><<unk>~<pad>%\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u00006\\<pad>[<<pad>\u0000\u0000\u0000\u0000><\\7<unk>0#\u0000\u0000\u0000\u0000|&<pad><[#@~^%8^%|z^>3<unk>&>$<pad><@?#>6<9<\\q%/\n"
     ]
    }
   ],
   "source": [
    "sample_fast_n(gru, 1000, 'The song')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: not sure what happened on these last GRU runs - I've saw better output from it earlier today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = 2\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, n_fac, batch_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, hidden_size, num_layers, dropout=0.5)\n",
    "        self.l_out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "        self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        bs = inputs[0].size(0)\n",
    "        if self.hidden[0].size(1) != bs: self.init_hidden(bs)\n",
    "            \n",
    "        output, hidden = self.rnn(self.embedding(inputs), self.hidden)\n",
    "        self.hidden = [h.detach() for h in hidden]\n",
    "        output = self.l_out(output)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output.view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.batch_size = bs\n",
    "        self.hidden = (V(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)),\n",
    "                  V(torch.zeros(self.num_layers, self.batch_size, self.hidden_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(md.nt, N_HIDDEN, N_FAC, BS, N_LAYERS).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, lstm, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a9dfcee1d044f89ca5da2f8c1907a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      2.051773   1.929572  \n",
      "    1      1.901966   1.803464                               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8034644178809034]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(lstm, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f69937ed574025aefbaec84cf9d75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.833636   1.745305  \n",
      "    1      1.804563   1.716936                               \n",
      "    2      1.777726   1.693807                               \n",
      "    3      1.761292   1.677003                               \n",
      "    4      1.744707   1.663735                               \n",
      "    5      1.738745   1.65961                                \n",
      "    6      1.73028    1.649545                               \n",
      "    7      1.722723   1.644285                               \n",
      "    8      1.714549   1.646497                               \n",
      "    9      1.709059   1.638595                               \n",
      "    10     1.704825   1.629268                               \n",
      "    11     1.69096    1.627913                               \n",
      "    12     1.693105   1.625921                               \n",
      "    13     1.685885   1.619073                               \n",
      "    14     1.680364   1.620328                               \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6203280507619657]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2)]\n",
    "fit(lstm, md, 2**4-1, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0000\u0000\u0000\n",
      "\n",
      "jana heaviously\n",
      "some. joshy band  \n",
      "\n",
      "awayol-impo love to dreak his out ***********\n",
      "\n",
      " <eot with of you befously sofic sad dy** are  \n",
      "\n",
      "pist blospapiteries of a produres has soon spic bort of the f-acomore themicsy\" is a created the many**)\n",
      "\n",
      "**ger_ //  \n",
      ">\n",
      "\n",
      "> the of spect of\n",
      "famic\n",
      "\n",
      "toomed.\"\n",
      "\n",
      "thei, lyrit. enjo: 'her cames. gettleator care, smous **caley\n",
      "**chouse**, \"dalco fourn indually, do singly to the hear inton awd a mul and sule it alson overity tractor calling (and peoplys is\n",
      "undent_ and to of strulation, secod, elec, boak norn, i would compored, sumb books, asking to going few lout. theing has at arts we relee, the face, noted * choines willots even:\" gaod spolle, ttis become maved shar shoots withation\".\n",
      "\n",
      " <eots any alreusition open may billings up like a broor fouran_, fa lovels with - songing the does have haungy lood smemotions of throons is the up thation aties thate, may it reling, so checed led bothers) news a borm pairs,\n",
      "thate now the cat delotolit outs to early what pakeran\n"
     ]
    }
   ],
   "source": [
    "sample_fast_n(lstm, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The song yourself  postir w/ style as quality at ourganique melodic is kettered right scack, is feels to\n",
      "be via stay but their suffles a beautifution, blaun of playing any for his now they succed follow from pop who is everything that had\n",
      "song _paying give of the before paging the artist lp for\n",
      "stail\n",
      "\n",
      " <eos> it's\n",
      "own all of question, also by habe vocals life hore to dreeped \"babear producer that will be connect of\n",
      "first march 24, enevernes stardy crand enjoy strunstnes. a whole prifting\n",
      "commo on expection of based she's finting, you're of you willly work on this informatioverharising\n",
      "a\n",
      "album to channies artists', the self-track, which something solid around. experiens\n",
      "me sobet pop couple below, like support\n",
      "\n",
      "trip as go to until that nom they desagnes\n",
      "is announces), but play for her forthcome to a that single of 19 -- sc now on **syn and deliver flow six and dio inspired\n",
      "for a life's beautiful is freezo (and she below make so green for they heartful, citare\n",
      "guriting music of far work off to the\n"
     ]
    }
   ],
   "source": [
    "sample_fast_n(lstm, 1000, 'The song')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa0e43024634599856f10028cd38f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=63), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.680109   1.61768   \n",
      "    1      1.680247   1.609803                               \n",
      "    2      1.672167   1.611287                               \n",
      "    3      1.67349    1.603189                               \n",
      "    4      1.6676     1.598211                               \n",
      "    5      1.660099   1.599367                               \n",
      " 23%|       | 125/547 [00:00<00:02, 173.41it/s, loss=1.66]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-19eb0a053b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCosAnneal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/openai/nbs/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openai/nbs/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2)]\n",
    "fit(lstm, md, 2**6-1, lo.opt, F.nll_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
